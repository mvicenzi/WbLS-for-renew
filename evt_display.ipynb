{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Event display for WbLS data\n",
        "add brief intro..."
      ],
      "metadata": {
        "id": "td9ccDivKIc3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Setting up the environment\n",
        "As always, we start by loading some Python packages that will be useful along the way.\n",
        "Google Colab provides several pre-installed libraries that can be directly imported. Additional packages can be installed using `!pip install`."
      ],
      "metadata": {
        "id": "R4bWfD1jKqFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# these packages are already available in Colab\n",
        "import os\n",
        "import sys\n",
        "import re\n",
        "import glob\n",
        "import statistics\n",
        "import pandas as pd\n",
        "import types\n",
        "import numpy as np\n",
        "from numpy import array, isscalar, uint16, uint32\n",
        "from numpy import sqrt\n",
        "from datetime import datetime\n",
        "from scipy.stats import norm\n",
        "\n",
        "# these packages require to be installed\n",
        "!pip install iminuit\n",
        "from iminuit import Minuit\n",
        "!pip install uproot\n",
        "import uproot\n",
        "!pip install numba\n",
        "!pip install lmfit\n",
        "\n",
        "print(\"uproot version:\", uproot.__version__)"
      ],
      "metadata": {
        "id": "LqPWzgTwJOYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is mounting a Google Drive access point, so that data files can be easily accessed. Moreover, this analysis requires a series of pre-written Python modules that will also be stored and accessed via Google Drive.\n",
        "\n",
        "1.   Run the following cell and follow the instructions in the popup dialog to grant access to the Google Drive connected to your account.\n",
        "2.   Go to [this Google Drive folder](https://drive.google.com/drive/folders/14SvWSV2c8bupNo5_yVhbXJ_kzsbUB6m_?usp=drive_link) and copy your collected data file to your Google Drive.\n",
        "3.   Go to [this Google Drive folder](https://drive.google.com/drive/folders/14SvWSV2c8bupNo5_yVhbXJ_kzsbUB6m_?usp=drive_link) and copy the `modules` folder in your Google Drive.\n",
        "4.   Fill the paths to your files/folders in the code. You can also copy the path by esploring the navigation menu on the left side of this page."
      ],
      "metadata": {
        "id": "wryOLl3aMOs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PkEqaweoMT6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fill out the path to the 'modules' folder in your Google Drive\n",
        "# e.g.: /content/drive/MyDrive/RENEW_DATA-Week_1/modules\n",
        "MODULES_PATH = \"/content/drive/MyDrive/RENEW_DATA-Week_1/modules\"\n",
        "\n",
        "# fill out the path to your collected data file in your Google Drive\n",
        "# e.g.: /content/drive/MyDrive/RENEW_DATA-Week_1/phase2_wbls_1pct_muon_mid_x64_19mV_alpha_2023_0625_0.root\n",
        "FILE_PATH = \"/content/drive/MyDrive/RENEW_DATA-Week_1/sample_data_WbLS/phase2_wbls_1pct_muon_mid_x64_19mV_alpha_2023_0625_0.root\""
      ],
      "metadata": {
        "id": "AB3lmy9oKBwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell uses the paths you provided to setup the pre-written Python modules, so that they can be referenced inside the notebook.\n",
        "\n",
        "These pre-existing modules come from the [DROP](https://github.com/BNLIF/drop) reconstruction software."
      ],
      "metadata": {
        "id": "__wOUmaHK0jL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SRC_DIR = MODULES_PATH+\"/src\"\n",
        "YAML_DIR = MODULES_PATH+\"/yaml\"\n",
        "LIB_DIR = MODULES_PATH+\"/lib\"\n",
        "TOOL_DIR = MODULES_PATH+\"/tools\"\n",
        "os.environ['LIB_DIR'] = LIB_DIR\n",
        "os.environ['YAML_DIR'] = YAML_DIR\n",
        "os.environ['SRC_DIR'] = SRC_DIR\n",
        "os.environ['TOOL_DIR'] = TOOL_DIR\n",
        "CALIB_FILE = MODULES_PATH+\"/calib/bnl1t_spe_fit_results_230420T1832.csv\"\n",
        "CONFIG_PATH = MODULES_PATH+\"/config_guang.yaml\"\n",
        "\n",
        "sys.path.append(SRC_DIR)\n",
        "os.system(MODULES_PATH+\"/src/make_numba_lib.py\")\n",
        "\n",
        "from utilities import generate_colormap\n",
        "from run_drop import RunDROP\n",
        "from waveform import Waveform\n",
        "from yaml_reader import YamlReader\n",
        "from pulse_finder import PulseFinder\n",
        "from yaml_reader import SAMPLE_TO_NS"
      ],
      "metadata": {
        "id": "4tmezzFsqz42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up some `matplotlib` default parameters:"
      ],
      "metadata": {
        "id": "pnC_J8vEN2Po"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "plotting preferences\n",
        "\"\"\"\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "plt.rcParams[\"font.size\"] = 14\n",
        "# matplotlib.rcParams['figure.figsize'] = [width, height]\n",
        "plt.rcParams['figure.figsize'] = [15, 8]"
      ],
      "metadata": {
        "id": "TO4Npv8eqYT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: blabla\n"
      ],
      "metadata": {
        "id": "TyGj771LJB0a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxsnmSBxJCDU"
      },
      "outputs": [],
      "source": [
        "def extract_datetime_from_str(s):\n",
        "    \"\"\"\n",
        "    Extract datatime from a str. The datetime must follow the fixed format:\n",
        "    YYmmddTHHMM\n",
        "    \"\"\"\n",
        "    #print (s)\n",
        "    #match = re.search(r'\\d{6}T\\d{4}', s)\n",
        "    match = re.search('\\d{6}T\\d{4}', s)\n",
        "\n",
        "    if match:\n",
        "        #print (match.group())\n",
        "        try:\n",
        "            dt = datetime.strptime(match.group(), '%y%m%dT%H%M')\n",
        "            #print (\"dt\" ,dt)\n",
        "            return dt\n",
        "        except ValueError:\n",
        "            print('Fail finding the datetime string from path: %s' % s)\n",
        "\n",
        "class WaveformFitter():\n",
        "    def __init__(self, raw_data_path, yaml_path='yaml/config.yaml'):\n",
        "        \"\"\"\n",
        "        Constructor. Make a superclass using DROP modules.\n",
        "\n",
        "        Args:\n",
        "            raw_data_path (str): path to the raw root file\n",
        "            yaml_path (str): path to the configuration yaml file (default:\n",
        "                yaml/config.yaml)\n",
        "        \"\"\"\n",
        "        self.cfg = YamlReader(yaml_path) # load yaml config\n",
        "        self.if_path = raw_data_path\n",
        "        self.load_run_info()\n",
        "        self.load_pmt_info()\n",
        "        #print ('calibration loaded')\n",
        "\n",
        "        # get daq tree via uproot\n",
        "        #print (\"uproot opening\")\n",
        "        f = uproot.open(raw_data_path)\n",
        "        #print ('getting entry number ', f['daq'].num_entries)\n",
        "        self.n_entries = f['daq'].num_entries\n",
        "        #print ('setting waveform')\n",
        "        self.wfm = Waveform(self.cfg)\n",
        "        #print ('setting ch names')\n",
        "        self.wfm.ch_names=self.ch_names\n",
        "        #print ('setting chn id')\n",
        "        self.wfm.ch_id = self.ch_id\n",
        "        #print ('setting nboards')\n",
        "        self.wfm.n_boards = self.n_boards\n",
        "        #print ('setting spe mean')\n",
        "        self.wfm.spe_mean = self.spe_mean\n",
        "        #print ('dat arrays')\n",
        "        #for mm in range(500):\n",
        "        self.daq = f['daq'].arrays()\n",
        "        #print ('entry id return')\n",
        "        self.entry_id = 0\n",
        "        #print ('done')\n",
        "\n",
        "    def load_run_info(self):\n",
        "        \"\"\"\n",
        "        I copied this function from run_drop.py\n",
        "        \"\"\"\n",
        "        f = uproot.open(self.if_path)\n",
        "        dt = extract_datetime_from_str(self.if_path)\n",
        "        a = f['run_info'].arrays(['n_boards', 'active_ch_id', 'n_event_proc'], library='np')\n",
        "        self.n_boards = uint16(a['n_boards'][0])\n",
        "        self.n_event_proc = uint32(a['n_event_proc'][0])\n",
        "        tmp = a['active_ch_id'][0]\n",
        "        if isscalar(tmp): # if only 1 active channels, tmp is a scalar and sort will fail\n",
        "            tmp = [tmp]\n",
        "        self.ch_id = sorted(uint16(tmp))\n",
        "        self.ch_names = [\"adc_b%d_ch%d\" % (i // 100, i % 100) for i in self.ch_id]\n",
        "        self.ch_name_to_id_dict = dict(zip(self.ch_names, self.ch_id))\n",
        "\n",
        "    def load_pmt_info(self):\n",
        "        \"\"\"\n",
        "        I copied this function from run_drop.py\n",
        "        \"\"\"\n",
        "        self.spe_mean = {}\n",
        "        fpath = CALIB_FILE #self.cfg.spe_fit_results_file\n",
        "        if self.cfg.interpolate_spe:\n",
        "            dt = extract_datetime_from_str(self.if_path)\n",
        "            fdir = os.path.dirname(fpath)\n",
        "            print (fdir)\n",
        "            led_paths=glob.glob(\"%s/drop/calib/*.csv\" % fdir)\n",
        "            p0, p1 = None, None\n",
        "            t0, t1 = 999999, 999999 # arbitary large\n",
        "            for p in led_paths:\n",
        "                #print (\"extract_datetime_from_str \", extract_datetime_from_str(p))\n",
        "                if (extract_datetime_from_str(p) == None):\n",
        "                    continue\n",
        "                delta = dt-extract_datetime_from_str(p)\n",
        "                delta_min = delta.total_seconds()/60\n",
        "                if delta_min>=0:\n",
        "                    if abs(delta_min)<t0:\n",
        "                        t0 = abs(delta_min)\n",
        "                        p0 = p\n",
        "                else:\n",
        "                    if abs(delta_min)<t1:\n",
        "                        t1 = abs(delta_min)\n",
        "                        p1 = p\n",
        "            if p1 is None:\n",
        "                self._set_spe_result(p0)\n",
        "                #print('Info: using calibration results from', p0)\n",
        "            else:\n",
        "                self._set_spe_result(p0)\n",
        "                df0 = pd.read_csv(p0)\n",
        "                df1 = pd.read_csv(p1)\n",
        "                df0.set_index('ch_name', inplace=True)\n",
        "                df1.set_index('ch_name', inplace=True)\n",
        "                ch_names = df0.index\n",
        "                for ch in ch_names:\n",
        "                    x0 = df0['spe_mean'][ch]\n",
        "                    x1 = df1['spe_mean'][ch]\n",
        "                    self.spe_mean[ch] = x0 + (x1-x0)/(t0+t1) * t0\n",
        "                    # self.spe_fit_results['spe_mean'][ch] = self.spe_mean[ch]\n",
        "                    self.spe_fit_results.loc[ch, 'spe_mean'] = self.spe_mean[ch]\n",
        "                print('Info: Intepolate from calibration results', p0, 'and', p1)\n",
        "        else:\n",
        "            self._set_spe_result(fpath)\n",
        "            #print('Info: using calibration results from', fpath)\n",
        "\n",
        "    def _set_spe_result(self, fpath):\n",
        "        \"\"\"\n",
        "        I copied this function from run_drop.py\n",
        "        \"\"\"\n",
        "        try:\n",
        "            df = pd.read_csv(fpath)\n",
        "            df.set_index('ch_name', inplace=True)\n",
        "            self.spe_fit_results  = df # to be saved in root\n",
        "            ch_names = df.index\n",
        "            for ch in ch_names:\n",
        "                self.spe_mean[ch] = float(df['spe_mean'][ch])\n",
        "        except:\n",
        "            sys.exit(\"your spe_fit_results_file cannot be loaded properly!\")\n",
        "\n",
        "    def process_one(self, i):\n",
        "        \"\"\"\n",
        "        Different name. Similar to a function in run_drop.py. Given an entry index, process that entry.\n",
        "        \"\"\"\n",
        "        self.event_id = self.daq[i].event_id\n",
        "        self.event_ttt = self.daq[i].event_ttt\n",
        "        self.wfm.reset()\n",
        "        self.wfm.set_raw_data(self.daq[i])\n",
        "        self.wfm.find_saturation()\n",
        "        self.wfm.subtract_flat_baseline()\n",
        "            #wfm.find_ma_baseline()\n",
        "        self.wfm.do_spe_normalization()\n",
        "        self.wfm.define_trigger_position()\n",
        "        self.wfm.correct_daisy_chain_trg_delay()\n",
        "        self.wfm.sum_channels()\n",
        "        self.wfm.define_time_axis()\n",
        "        self.wfm.integrate_waveform()\n",
        "        self.wfm.calc_roi_info()\n",
        "        self.wfm.calc_aux_ch_info()\n",
        "\n",
        "    def process_next(self):\n",
        "        \"\"\"\n",
        "        Put process one in a loop\n",
        "        \"\"\"\n",
        "        if self.entry_id<self.n_entries:\n",
        "            i = self.entry_id\n",
        "            self.process_one(i)\n",
        "            self.entry_id+=1\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def get_wfm_data(self, t_min=370, t_max=470, ch_name='sum_bot'):\n",
        "        \"\"\"\n",
        "        Arg:\n",
        "            t_min: float\n",
        "            t_max: float\n",
        "            ch_name: channel names identical to how it's defined in DROP.\n",
        "        Options: sum_bot, sum_side, sum_row1,..., sum_row4, ..., sum_col1,..., sum_col4.\n",
        "        Individual channels are accessible too. For example, adc_b1_ch3 is board 1 channel 3.\n",
        "        \"\"\"\n",
        "        t = self.wfm.time_axis_ns\n",
        "        mask = (t>=t_min) & (t<t_max)\n",
        "        x_data=t[mask]\n",
        "        #y_data=wf.wfm.amp_pe[ch_name][mask]\n",
        "        y_data=self.wfm.amp_pe[ch_name][mask]\n",
        "        return x_data, y_data\n",
        "\n",
        "    def get_wfm_data_mv(self, t_min=370, t_max=470, ch_name='sum_bot'):\n",
        "        \"\"\"\n",
        "        Arg:\n",
        "            t_min: float\n",
        "            t_max: float\n",
        "            ch_name: channel names identical to how it's defined in DROP.\n",
        "        Options: sum_bot, sum_side, sum_row1,..., sum_row4, ..., sum_col1,..., sum_col4.\n",
        "        Individual channels are accessible too. For example, adc_b1_ch3 is board 1 channel 3.\n",
        "        \"\"\"\n",
        "        t = self.wfm.time_axis_ns\n",
        "        #mask = (t>=t_min) & (t<t_max)\n",
        "        #x_data=t[mask]\n",
        "        x_data=t\n",
        "        y_data=self.wfm.amp_mV[ch_name]\n",
        "        #y_data=self.wfm.amp_mV[ch_name][mask]\n",
        "\n",
        "        return x_data, y_data\n",
        "\n",
        "    def get_aux_ch_mV(self, ch_name='adc_b1_ch0'):\n",
        "        return self.wfm.aux_ch_area_mV[ch_name]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3:\n"
      ],
      "metadata": {
        "id": "ECJpa-QDNhPv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSU4eLWTJCDY"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Example: usage of WaveformFitter class (feel free to change the class name since\n",
        "there is no fitting method currently implemented).\n",
        "\"\"\"\n",
        "\n",
        "event_start_time=-1\n",
        "event_end_time=-1\n",
        "# define path to your raw root file\n",
        "DATA_DIR='/content/drive/MyDrive/RENEW_DATA-Week_1'\n",
        "ch_string = \"\"\n",
        "\n",
        "for i in range(15):\n",
        "    ch_string += \"adc_b1_ch{} \".format(i+1)\n",
        "for i in range(15):\n",
        "    ch_string += \"adc_b2_ch{} \".format(i)\n",
        "for i in range(16):\n",
        "    ch_string += \"adc_b3_ch{} \".format(i)\n",
        "for i in range(12):\n",
        "    ch_string += \"adc_b4_ch{} \".format(i)\n",
        "\n",
        "#print (ch_string)\n",
        "\n",
        "#for word in ch_string.split():\n",
        "#    print (word)\n",
        "\n",
        "def display_charge(chg):\n",
        "    dis_x=[]\n",
        "    dis_y=[]\n",
        "    area=[]\n",
        "    area2=[]\n",
        "    locx_bot = [381, 381, 381, 381,\n",
        "            190.5, 190.5, 190.5, 190.5, 190.5, 190.5, 190.5,\n",
        "            0, 0, 0, 0, 0, 0, 0, 0,\n",
        "           -190.5, -190.5, -190.5, -190.5, -190.5, -190.5, -190.5,\n",
        "           -381, -381, -381, -381]\n",
        "    locy_bot = [-171.45, -57.15, 57.15, 171.45,\n",
        "           -342.9, -228.6, -114.3, 0, 114.3, 228.6, 342.9,\n",
        "           -400.05, -285.75, -171.45, -57.15,57.15, 171.45, 285.75, 400.05,\n",
        "           -342.9, -228.6, -114.3, 0, 114.3, 228.6, 342.9,\n",
        "           -171.45, -57.15, 57.15, 171.45]\n",
        "    locx_side= [-532.955, -532.955,-532.955,-532.955,\n",
        "               532.955,532.955,532.955,532.955,\n",
        "               0,0,0,0,0,0,0,0,]\n",
        "    locy_side= [0,0,0,0,0,0,0,0,\n",
        "               -532.955, -532.955,-532.955,-532.955,\n",
        "               532.955,532.955,532.955,532.955]\n",
        "    locz_side= [-495.3, -336.55, 222.25, 393.7,\n",
        "               -495.3, -336.55, 222.25, 393.7,\n",
        "               -495.3, -336.55, 222.25, 393.7,\n",
        "               -495.3, -336.55, 222.25, 393.7]\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "    plt.rcParams['figure.figsize'] = [10, 4]\n",
        "    for i in range(len(chg)):\n",
        "        if i < 30:\n",
        "            area.append(chg[i]*50)\n",
        "        elif i < 46:\n",
        "            if i>29 and i<34:\n",
        "                dis_x.append(0)\n",
        "            if i>33 and i<38:\n",
        "                dis_x.append(180)\n",
        "            if i>37 and i<42:\n",
        "                dis_x.append(90)\n",
        "            if i>41 and i<46:\n",
        "                dis_x.append(270)\n",
        "            dis_y.append(locz_side[i-30])\n",
        "            area2.append(chg[i-30]*50)\n",
        "    ax1.scatter(locx_bot, locy_bot, s=area, c=\"Blue\", alpha=1, label=\"Bottom plane\")\n",
        "    ax2.scatter(dis_x, dis_y, s=area2, c=\"Blue\", alpha=1, label=\"Barrel plane\")\n",
        "    ax1.set_xlabel(\"X (mm)\")\n",
        "    ax1.set_ylabel(\"Y (mm)\")\n",
        "    ax2.set_xlabel(\"$\\phi$ (deg.) with R = 533 mm\")\n",
        "    ax2.set_ylabel(\"Z (mm)\")\n",
        "    ax1.legend(loc='upper right')\n",
        "    ax2.legend(loc='upper right')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4:"
      ],
      "metadata": {
        "id": "rQJlR_IlNpij"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCXfIa72JCDZ"
      },
      "outputs": [],
      "source": [
        "from scipy.optimize import curve_fit\n",
        "#from lmfit.models import GaussianModel\n",
        "from lmfit import Model\n",
        "tmin = 350\n",
        "tmax = 430\n",
        "\n",
        "class processor():\n",
        "    def __init__(self):\n",
        "        print(\"processor ready\")\n",
        "\n",
        "    def process_data(self, dtime, nevts, nruns, exa):\n",
        "\n",
        "        tmin = 220\n",
        "        tmax = 320\n",
        "        tt = []\n",
        "        tt_mv1 = []\n",
        "\n",
        "        for ie in range(nruns):\n",
        "\n",
        "            data_path= FILE_PATH\n",
        "            wf = WaveformFitter(data_path, CONFIG_PATH)\n",
        "\n",
        "            for ii in range(nevts):\n",
        "\n",
        "                # process the first entry\n",
        "                #print ('processing one event')\n",
        "                wf.process_one(ii)\n",
        "                event_id=wf.event_id\n",
        "                event_ttt=wf.event_ttt\n",
        "                #print('run_id:', run_id, \"event_id:\", event_id, \"event_ttt:\", event_ttt)\n",
        "\n",
        "                evt_chg=[]\n",
        "                chn_count = 0\n",
        "                # get the data between t_min and t_max.\n",
        "                for ich in ch_string.split():\n",
        "                    if chn_count>45:\n",
        "                        break\n",
        "                    if \"adc\" in ich:\n",
        "                        chn_count += 1\n",
        "                        x_data, y_data = wf.get_wfm_data(t_min=0, t_max=2000, ch_name='{}'.format(ich))\n",
        "                    else:\n",
        "                        print (\"can't do this channel\")\n",
        "\n",
        "                    yy_data = y_data.tolist()\n",
        "                    aa = yy_data.index(np.max(yy_data))\n",
        "\n",
        "                    tmin = x_data[aa] - 20\n",
        "                    tmax = x_data[aa] + 40\n",
        "\n",
        "                    if np.max(y_data) > -1e9:\n",
        "                        if \"adc\" in ich:\n",
        "                            x_data_mv, y_data_mv = wf.get_wfm_data(t_min=tmin, t_max=tmax, ch_name='{}'.format(ich))\n",
        "                        else:\n",
        "                            print (\"can't do this channel\")\n",
        "                        summ_mv = 0\n",
        "                        for idata in range(len(y_data_mv)):\n",
        "                            summ_mv += y_data_mv[idata]*2\n",
        "                        evt_chg.append(summ_mv)\n",
        "                        if exa and chn_count<10:\n",
        "                            plt.subplot(3,3,chn_count)\n",
        "                            plt.plot(x_data_mv, y_data_mv, color='k', label='channel %s'%ich)\n",
        "                    if exa:\n",
        "                        plt.legend()\n",
        "\n",
        "                if (wf.get_aux_ch_mV(ch_name='adc_b1_ch0') +wf.get_aux_ch_mV(ch_name='adc_b2_ch15')>300 ):\n",
        "                    print (\"this is a crossing muon.\")\n",
        "                else:\n",
        "                    print (\"this is not a crossing muon.\")\n",
        "\n",
        "                display_charge(evt_chg)\n",
        "\n",
        "            del wf\n",
        "\n",
        "        back_array = []\n",
        "        return back_array\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "QApjJ53SJCDZ"
      },
      "outputs": [],
      "source": [
        "all_date = \"0625 \"\n",
        "nevt =10\n",
        "show_example=False\n",
        "for dtime in all_date.split():\n",
        "    print (\"doing day with event number \", dtime,' ',nevt)\n",
        "    pr = processor()\n",
        "    # arguments: date of the day, number of events, number of runs - should be 1, if want to show waveform examples\n",
        "    result = pr.process_data(dtime, nevt, 1, show_example)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZBXtpciJCDa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}